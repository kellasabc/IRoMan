#!/usr/bin/env python3
"""
æµ‹è¯•Diffusionæ¨¡å‹åŠ è½½è„šæœ¬
éªŒè¯æ¼”ç¤ºè„šæœ¬æ˜¯å¦èƒ½æ­£ç¡®åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
"""

import os
import sys
import torch
import dill
import hydra
from omegaconf import OmegaConf

# Add diffusion_copolicy to path
current_dir = os.path.dirname(os.path.abspath(__file__))
workspace_root = os.path.join(current_dir, '..', '..', '..')
diffusion_copolicy_path = os.path.join(workspace_root, 'diffusion_copolicy')
sys.path.append(diffusion_copolicy_path)
sys.path.append(os.path.join(diffusion_copolicy_path, 'diffusion_policy'))

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("=== æµ‹è¯•Diffusionæ¨¡å‹åŠ è½½ ===")
    
    # æ¨¡å‹è·¯å¾„
    model_path = os.path.join(workspace_root, "diffusion_copolicy", "data", "outputs", "diffusion_model_lifting_no_human_cond", "best_model.ckpt")
    
    print(f"æ¨¡å‹è·¯å¾„: {model_path}")
    print(f"æ¨¡å‹æ–‡ä»¶å­˜åœ¨: {os.path.exists(model_path)}")
    
    if not os.path.exists(model_path):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼")
        return False
    
    try:
        # åŠ è½½æ£€æŸ¥ç‚¹
        print("æ­£åœ¨åŠ è½½æ£€æŸ¥ç‚¹...")
        checkpoint = torch.load(model_path, map_location="cpu", pickle_module=dill)
        print("âœ“ æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ")
        
        # æ£€æŸ¥é…ç½®
        if 'cfg' in checkpoint:
            cfg = checkpoint['cfg']
            print("âœ“ é…ç½®åŠ è½½æˆåŠŸ")
            print(f"  - ä»»åŠ¡åç§°: {cfg.get('name', 'æœªçŸ¥')}")
            print(f"  - è§‚å¯Ÿç»´åº¦: {cfg.get('obs_dim', 'æœªçŸ¥')}")
            print(f"  - åŠ¨ä½œç»´åº¦: {cfg.get('action_dim', 'æœªçŸ¥')}")
            print(f"  - Human action ä½œä¸ºæ¡ä»¶: {cfg.get('human_act_as_cond', 'æœªçŸ¥')}")
            print(f"  - è§‚å¯Ÿæ­¥æ•°: {cfg.get('n_obs_steps', 'æœªçŸ¥')}")
            print(f"  - é¢„æµ‹é•¿åº¦: {cfg.get('horizon', 'æœªçŸ¥')}")
        else:
            print("âš  é…ç½®ä¿¡æ¯ç¼ºå¤±")
            return False
        
        # æ£€æŸ¥æ¨¡å‹æƒé‡
        if 'model_state_dict' in checkpoint:
            print("âœ“ æ¨¡å‹æƒé‡å­˜åœ¨ (model_state_dict)")
            model_state_dict = checkpoint['model_state_dict']
        elif 'state_dicts' in checkpoint:
            print("âœ“ æ¨¡å‹æƒé‡å­˜åœ¨ (state_dicts)")
            model_state_dict = checkpoint['state_dicts']['model']
        else:
            print("âš  æ¨¡å‹æƒé‡ç¼ºå¤±")
            return False
        
        # æ£€æŸ¥normalizer
        if 'normalizer_state_dict' in checkpoint:
            print("âœ“ Normalizerå­˜åœ¨")
        elif 'state_dicts' in checkpoint and 'normalizer' in checkpoint['state_dicts']:
            print("âœ“ Normalizerå­˜åœ¨ (state_dicts)")
        else:
            print("âš  Normalizerç¼ºå¤±")
        
        # å°è¯•åˆ›å»ºæ¨¡å‹å®ä¾‹
        print("æ­£åœ¨åˆ›å»ºæ¨¡å‹å®ä¾‹...")
        from diffusion_policy.model.diffusion.transformer_for_diffusion import TransformerForDiffusion
        
        # æ‰‹åŠ¨è§£ææ¨¡å‹é…ç½®
        model_config = cfg.policy.model
        model = TransformerForDiffusion(
            input_dim=model_config.input_dim,
            output_dim=model_config.output_dim,
            horizon=model_config.horizon,
            n_obs_steps=model_config.n_obs_steps,
            cond_dim=model_config.cond_dim,
            n_layer=model_config.n_layer,
            n_head=model_config.n_head,
            n_emb=model_config.n_emb,
            p_drop_emb=model_config.p_drop_emb,
            p_drop_attn=model_config.p_drop_attn,
            causal_attn=model_config.causal_attn,
            time_as_cond=model_config.time_as_cond,
            obs_as_cond=model_config.obs_as_cond,
            human_act_as_cond=model_config.human_act_as_cond,
            n_cond_layers=model_config.n_cond_layers,
        )
        print("âœ“ æ¨¡å‹å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # å°è¯•åŠ è½½æƒé‡
        print("æ­£åœ¨åŠ è½½æ¨¡å‹æƒé‡...")
        if any(key.startswith("model.") for key in model_state_dict.keys()):
            print("âœ“ æ£€æµ‹åˆ° 'model.' å‰ç¼€ï¼Œæ­£åœ¨ç§»é™¤...")
            new_state_dict = {}
            for key, value in model_state_dict.items():
                if key.startswith("model."):
                    new_key = key[6:]  # Remove "model." prefix
                    new_state_dict[new_key] = value
                else:
                    new_state_dict[key] = value
            model_state_dict = new_state_dict
        
        model.load_state_dict(model_state_dict)
        print("âœ“ æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
        
        # å°è¯•åˆ›å»ºç­–ç•¥
        print("æ­£åœ¨åˆ›å»ºç­–ç•¥å®ä¾‹...")
        from diffusion_policy.policy.diffusion_transformer_lowdim_policy import DiffusionTransformerLowdimPolicy
        from diffusers.schedulers.scheduling_ddpm import DDPMScheduler
        
        # æ‰‹åŠ¨åˆ›å»ºnoise scheduler
        noise_scheduler = DDPMScheduler(
            num_train_timesteps=cfg.policy.noise_scheduler.num_train_timesteps,
            beta_start=cfg.policy.noise_scheduler.beta_start,
            beta_end=cfg.policy.noise_scheduler.beta_end,
            beta_schedule=cfg.policy.noise_scheduler.beta_schedule,
            variance_type=cfg.policy.noise_scheduler.variance_type,
            clip_sample=cfg.policy.noise_scheduler.clip_sample,
            prediction_type=cfg.policy.noise_scheduler.prediction_type,
        )
        
        # æ‰‹åŠ¨åˆ›å»ºç­–ç•¥
        policy = DiffusionTransformerLowdimPolicy(
            model=model,
            noise_scheduler=noise_scheduler,
            horizon=cfg.policy.horizon,
            obs_dim=cfg.policy.obs_dim,
            action_dim=cfg.policy.action_dim,
            n_action_steps=cfg.policy.n_action_steps,
            n_obs_steps=cfg.policy.n_obs_steps,
            num_inference_steps=cfg.policy.num_inference_steps,
            obs_as_cond=cfg.policy.obs_as_cond,
            human_act_as_cond=cfg.policy.human_act_as_cond,
            pred_action_steps_only=cfg.policy.pred_action_steps_only,
            robot_action_dim=cfg.policy.robot_action_dim,
            human_action_dim=cfg.policy.human_action_dim,
        )
        print("âœ“ ç­–ç•¥å®ä¾‹åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥è®¾å¤‡
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"âœ“ ä½¿ç”¨è®¾å¤‡: {device}")
        
        # ç§»åŠ¨åˆ°è®¾å¤‡
        policy.eval().to(device)
        print("âœ“ æ¨¡å‹ç§»åŠ¨åˆ°è®¾å¤‡æˆåŠŸ")
        
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½å’Œä½¿ç”¨ã€‚")
        return True
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_observation_processing():
    """æµ‹è¯•è§‚å¯Ÿå¤„ç†"""
    print("\n=== æµ‹è¯•è§‚å¯Ÿå¤„ç† ===")
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„23ç»´è§‚å¯Ÿ
    obs_23d = np.random.randn(23).astype(np.float32)
    print(f"âœ“ åˆ›å»º23ç»´è§‚å¯Ÿ: {obs_23d.shape}")
    
    # è½¬æ¢ä¸ºtensor
    obs_tensor = torch.from_numpy(obs_23d)
    print(f"âœ“ è½¬æ¢ä¸ºtensor: {obs_tensor.shape}")
    
    # æ¨¡æ‹Ÿè§‚å¯Ÿç¼“å†²åŒº
    n_obs_steps = 2
    obs_buffer = obs_tensor.unsqueeze(0).repeat(n_obs_steps, 1)
    print(f"âœ“ åˆ›å»ºè§‚å¯Ÿç¼“å†²åŒº: {obs_buffer.shape}")
    
    # æ·»åŠ æ‰¹æ¬¡ç»´åº¦
    obs_dict = {"obs": obs_buffer.unsqueeze(0)}
    print(f"âœ“ æ·»åŠ æ‰¹æ¬¡ç»´åº¦: {obs_dict['obs'].shape}")
    
    print("âœ“ è§‚å¯Ÿå¤„ç†æµ‹è¯•é€šè¿‡ï¼")
    return True

if __name__ == "__main__":
    import numpy as np
    
    success = True
    
    # æµ‹è¯•æ¨¡å‹åŠ è½½
    success &= test_model_loading()
    
    # æµ‹è¯•è§‚å¯Ÿå¤„ç†
    success &= test_observation_processing()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ¼”ç¤ºè„šæœ¬åº”è¯¥å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
        print("\nä½¿ç”¨æ–¹æ³•:")
        print("1. æ— äººç±»æ¡ä»¶ç‰ˆæœ¬:")
        print("   python demo_collaborative_lifting_diffusion.py")
        print("2. æœ‰äººç±»æ¡ä»¶ç‰ˆæœ¬:")
        print("   python demo_collaborative_lifting_diffusion_human_condition.py")
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å’Œä¾èµ–ã€‚")
